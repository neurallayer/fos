{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from fos import Supervisor, Trainer\n",
    "from fos.meters import NotebookMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "This notebook demonstrates how to use **FOS** to train model that has multiple inputs and target values. It uses some dummy data and a model to demonstrate the pattern to use. There are three aspects that require some extra attention:\n",
    "\n",
    "1. The `data`, in this case a dataset. The dataset is used to return the two values for the input and the target. This is done by putting the input and target     values in their own tuple. The input and target values don't need to be of the same length, that depends on what your model expects and returns. The more generic pattern would be:\n",
    "\n",
    "        return (x1,x2,...,xn), (y1,y2,...ym)\n",
    "        \n",
    "        \n",
    "2. The `forward` method of the model gets the input (x) values as a tuple and can easily access them:\n",
    "\n",
    "        x1, x2, ...., xn = x\n",
    "        \n",
    "        \n",
    "3. Lastly the `loss` function get both the predicted values and target values as tuples and can access them \n",
    "the same way as the forward function. Here we combine two different lost function and return the sum of them. Although not \n",
    "used in this example, but the same would apply to any metrics you would like to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    '''Example dataset that returns two random values for the input \n",
    "       and two random values the target'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "    \n",
    "    def __getitem__(self, start):\n",
    "        x1 = torch.randn(10)\n",
    "        x2 = torch.randn(10)\n",
    "        y1 = torch.randn(2)\n",
    "        y2 = torch.randn(2)\n",
    "        return (x1, x2), (y1, y2)\n",
    "            \n",
    "\n",
    "class Predictor(nn.Module):\n",
    "    ''' A network with two fully connected layers and a `dummy` forward\n",
    "        that just performs some arbritrary operations.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 2)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x1, x2 = x\n",
    "        y1 = self.fc1(x1)-self.fc2(x2)\n",
    "        y2 = self.fc2(x1)+self.fc2(x2)\n",
    "        return y1, y2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss(pred, target):\n",
    "    '''An example loss function that demonstrates how to combine two \n",
    "       different losses for the two predictions.\n",
    "    ''' \n",
    "    p1, p2 = pred\n",
    "    t1, t2 = target\n",
    "    return F.mse_loss(p1, t1) + F.l1_loss(p2, t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "The rest is the same as with any other type of model. So please check the basic tutorial if this isn't clear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor().to(\"cuda\")\n",
    "optim     = torch.optim.Adam(predictor.parameters())\n",
    "data      = DataLoader(Dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "meter   = NotebookMeter()\n",
    "model   = Supervisor(predictor, combined_loss)\n",
    "trainer = Trainer(model, optim, meter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[  0:  1000] loss=2.32668 : 100%|██████████|00:02<00:00\n",
      "[  1:  2000] loss=1.87865 : 100%|██████████|00:02<00:00\n",
      "[  2:  3000] loss=1.80046 : 100%|██████████|00:02<00:00\n",
      "[  3:  4000] loss=1.80939 : 100%|██████████|00:02<00:00\n",
      "[  4:  5000] loss=1.83453 : 100%|██████████|00:02<00:00\n",
      "[  5:  6000] loss=1.85153 : 100%|██████████|00:02<00:00\n",
      "[  6:  7000] loss=1.84351 : 100%|██████████|00:02<00:00\n",
      "[  7:  8000] loss=1.76520 : 100%|██████████|00:02<00:00\n",
      "[  8:  9000] loss=1.83763 : 100%|██████████|00:02<00:00\n",
      "[  9: 10000] loss=1.85692 : 100%|██████████|00:02<00:00\n"
     ]
    }
   ],
   "source": [
    "trainer.run(data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
